{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras as ks\n",
    "from skimage import io\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = pd.read_csv('list_attr_celeba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "hair = pd.DataFrame(np.where(attr[['Black_Hair','Bald','Blond_Hair','Brown_Hair','Gray_Hair']] > 0, 1, 0),columns=['Black_Hair','Bald','Blond_Hair','Brown_Hair','Gray_Hair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "hair = hair[(hair.T != 0).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_images = hair.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing cv2 to help work with images\n",
    "import cv2\n",
    "\n",
    "# Creating a function to format images\n",
    "def load_images(path):\n",
    "    img_data = [] # return the image itself\n",
    "    index = [] # adds an index to reference image\n",
    "    x = -1\n",
    "    for pic in os.listdir(path):\n",
    "        pic_path = os.path.join(path,pic)\n",
    "        for img in os.listdir(pic_path):\n",
    "            x += 1\n",
    "            if x in target_images:\n",
    "                img_path = os.path.join(pic_path,img)\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.resize(image, (64, 64))\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                img_data.append(image)\n",
    "                index.append(x)\n",
    "    return(np.array(img_data),np.array(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up fill location for our load_images function\n",
    "train_path = 'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, img_num) = load_images(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      1,      5, ..., 202596, 202597, 202598])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, hair, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86416, 64, 64, 3)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Modeling Tools\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init Model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, (3, 3), input_shape=(64,64,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(16, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32,(3,3 )))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compiling Model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86416 samples, validate on 42564 samples\n",
      "Epoch 1/11\n",
      "86416/86416 [==============================] - 1927s 22ms/step - loss: 0.5206 - acc: 0.8244 - val_loss: 0.4287 - val_acc: 0.8518\n",
      "Epoch 2/11\n",
      "86416/86416 [==============================] - 1923s 22ms/step - loss: 0.4126 - acc: 0.8655 - val_loss: 0.4238 - val_acc: 0.8816\n",
      "Epoch 3/11\n",
      "86416/86416 [==============================] - 1919s 22ms/step - loss: 0.3829 - acc: 0.8767 - val_loss: 0.5292 - val_acc: 0.8385\n",
      "Epoch 4/11\n",
      "86416/86416 [==============================] - 1922s 22ms/step - loss: 0.3658 - acc: 0.8832 - val_loss: 0.6059 - val_acc: 0.8553\n",
      "Epoch 5/11\n",
      "86416/86416 [==============================] - 1920s 22ms/step - loss: 0.3521 - acc: 0.8883 - val_loss: 0.3787 - val_acc: 0.8708\n",
      "Epoch 6/11\n",
      "86416/86416 [==============================] - 1922s 22ms/step - loss: 0.3416 - acc: 0.8921 - val_loss: 0.4965 - val_acc: 0.8659\n",
      "Epoch 7/11\n",
      "86416/86416 [==============================] - 1917s 22ms/step - loss: 0.3312 - acc: 0.8964 - val_loss: 0.3439 - val_acc: 0.8935\n",
      "Epoch 8/11\n",
      "86416/86416 [==============================] - 1921s 22ms/step - loss: 0.3224 - acc: 0.9009 - val_loss: 0.4223 - val_acc: 0.8791\n",
      "Epoch 9/11\n",
      "86416/86416 [==============================] - 1921s 22ms/step - loss: 0.3120 - acc: 0.9031 - val_loss: 0.3786 - val_acc: 0.8873\n",
      "Epoch 10/11\n",
      "86416/86416 [==============================] - 1925s 22ms/step - loss: 0.3056 - acc: 0.9067 - val_loss: 0.4342 - val_acc: 0.8961\n",
      "Epoch 11/11\n",
      "86416/86416 [==============================] - 1921s 22ms/step - loss: 0.2970 - acc: 0.9099 - val_loss: 0.4221 - val_acc: 0.8855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f0059ca1d0>"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Model\n",
    "# higher batch and loss 32, .5\n",
    "model.fit(X_train,y_train, epochs=11, batch_size = 32,\n",
    "                    validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving predictions for new model\n",
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42564, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(42564,)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "pred = np_utils.to_categorical(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42564, 5)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " Black Hair       0.97      0.88      0.92     17675\n",
      "       Bald       0.77      0.81      0.79      1403\n",
      " Blond Hair       0.92      0.90      0.91     10216\n",
      " Brown Hair       0.75      0.94      0.83     10897\n",
      "  Gray Hair       0.74      0.86      0.79      2373\n",
      "\n",
      "avg / total       0.88      0.90      0.89     42564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing metrics\n",
    "print(classification_report(pred,y_test,target_names=['Black Hair','Bald','Blond Hair','Brown Hair','Gray Hair']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
